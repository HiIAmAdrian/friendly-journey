{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CU O SINGURA STARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abat Să simt ce vor înţelege... Dar mă cruţa, izbeşte!... iubite-i rândul tău: Închis, fără de beţie- I-auzi cum visează spume, cerurile-nşiră nori. Şi cum frunzele-n poiană Şoptesc cu splendoarea pupilei tale gene, suflã-i basm de unde să-nchidă, când şopteşte cu acel demon... s-ar stinge-n cer într-o crâşmă umedă, murdară. Prin vârfuri în altă dobândă, Slăvită-mpreunare de frumos, cum greu, îi înfiori... Oh, primăvara în nemurire! Ne aduni la fel. Şi azi acasă... Potop e-napoi şi-nainte, Te măsluieşti cu-o privire în seve, Trecutul nu apune, Preot deşteptării noastre, semnelor vremii nu s-ascundea nimica, deşi tot mereu în condei şi-ntr-un ciob de cristal. Iubito, eu singur Prin ploaie şi gând!... De serenadele albastre... De la dânsul ne cheamă... Singur, singur, Într-un han, departe- Doarme şi minte, te scuturi, tind spinii cu-ndrazneală. În zadar în pivniţa adâncă fără razem, fără a intrat în vesela grădină cu zgomote deşarte Vreme rea sau că e poezia? Înger palid se duse-acuma pe-a sa antică, Grea de piatră sură; Lucii picături de lege de veacuri încă, Pân' ce-oi simţi că tu ,bine, iubito, Chiar pân' la iezătură; Iar catapeteasma lumii doar mai trecut Şi o alunã, pe mlaștină. S-a-ntâlnit un dor Şi ce farmecă şi-nfrânge! Frumos\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def citeste_corpus(nume_fisier):\n",
    "    with open(nume_fisier, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "def construieste_lant_markov(tokens):\n",
    "    lant_markov = {}\n",
    "    for i in range(len(tokens) - 1):\n",
    "        cuvant_curent = tokens[i]\n",
    "        urmatorul_cuvant = tokens[i + 1]\n",
    "        if cuvant_curent not in lant_markov:\n",
    "            lant_markov[cuvant_curent] = []\n",
    "        lant_markov[cuvant_curent].append(urmatorul_cuvant)\n",
    "    return lant_markov\n",
    "\n",
    "def HAGIFICA(lant_markov, lungime_maxima=200):\n",
    "    proverb = []\n",
    "    cuvant_curent = random.choice(list(lant_markov.keys()))\n",
    "    for _ in range(lungime_maxima):\n",
    "        proverb.append(cuvant_curent)\n",
    "        urmatoarele_cuvinte_posibile = lant_markov.get(cuvant_curent, [])\n",
    "        if not urmatoarele_cuvinte_posibile:\n",
    "            break\n",
    "        cuvant_curent = random.choice(urmatoarele_cuvinte_posibile)\n",
    "    return ' '.join(proverb)\n",
    "\n",
    "text = citeste_corpus(\"../data/corpus_complet.txt\")\n",
    "tokens = text.split()\n",
    "lant_markov = construieste_lant_markov(tokens)\n",
    "proverb_generat = HAGIFICA(lant_markov)\n",
    "print(proverb_generat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cu n stari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parte. Nu da vrabia din mana pentru cioara de pe gard. Nu e dracul asa de negru. Nu este padure fara uscatura. Obrazul de scoarta totdeauna ii gata de harta. Ochii care nu face calul mai bun. Fuga e rusinoasa dar sanatoasa. Gaina batrana face ciorba buna. Gaina vecinului pare curca. Gaina in faina. Gand la gand cu bucurie. Gerul nu vine niciodata singur. Graba strica treaba. Haina nu il vezi pe cel mic. Pica para malaiata in gura lui Natafleata. Prea putin ca sa mori. Prieteni noi sa iti faci dar de mine mi se rupe inima. Minciuna are picioare scurte. Mortul de la groapa nu se vad se uita. Ochii sunt oglinda sufletului. Ochii sunt oglinda sufletului. Ochii verzi niciodata sa nu te lasi!. Printre grau malura creste. Prost sa fii noroc sa ai. Puneti frau la gura si lacat la inima. Prostul intai o croieste apoi o gandeste. Prostul nu e profet in tara orbilor chiorul este imparat. Jarul potolit te arde. Jur acum pana nu iese soarele. La placinte inainte la razboi inapoi. La pomul laudat sa nu te lasi!. Printre grau malura creste. Prost sa fii noroc sa ai. Puneti frau la gura si lacat\n"
     ]
    }
   ],
   "source": [
    "def construieste_lant_markov(tokens, n):\n",
    "    lant_markov = {}\n",
    "    for i in range(len(tokens) - n):\n",
    "        n_grama = tuple(tokens[i:i + n])\n",
    "        urmatorul_cuvant = tokens[i + n]\n",
    "        if n_grama not in lant_markov:\n",
    "            lant_markov[n_grama] = []\n",
    "        lant_markov[n_grama].append(urmatorul_cuvant)\n",
    "    return lant_markov\n",
    "\n",
    "def HAGIFICA(lant_markov, n, lungime_maxima=200):\n",
    "    proverb = []\n",
    "    index_initial = random.randint(0, len(tokens) - n)\n",
    "    n_grama_initiala = tuple(tokens[index_initial:index_initial + n])\n",
    "    proverb.extend(n_grama_initiala)\n",
    "    \n",
    "    for _ in range(lungime_maxima - n):\n",
    "        n_grama_curenta = tuple(proverb[-n:])\n",
    "        urmatoarele_cuvinte_posibile = lant_markov.get(n_grama_curenta, [])\n",
    "        if not urmatoarele_cuvinte_posibile:\n",
    "            break\n",
    "        urmatorul_cuvant = random.choice(urmatoarele_cuvinte_posibile)\n",
    "        proverb.append(urmatorul_cuvant)\n",
    "        \n",
    "    return ' '.join(proverb)\n",
    "\n",
    "text = citeste_corpus(\"../data/proverbe.txt\")\n",
    "tokens = text.split()\n",
    "n = 2\n",
    "lant_markov = construieste_lant_markov(tokens, n)\n",
    "text_generat = HAGIFICA(lant_markov, n)\n",
    "print(text_generat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problema 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tipsy revelry, Or at home and kingdom thus forego To carry speedy succour to that flight of shell, To Phoebus and the morning fills With shade the Plain Delight not all; Not only flew the splendid prize to win her: They prick a bleeding boast, I shall not be united. Since this must be appears sublime in state, And Lazarus, must go. And \"Mary smooth your bed, Smile soft in youth, with broken sighs and sobs were all they follow out their hands who’re not cleared it off without a pause, lightly:_ An elf of mischief long, Dame Europe had her fields unsown; But that I smiled amused and felt above him Lament their dear praise, One jot of their sight A baby. Though dark and the deadly fight; It is useless quite To stand aloof was safest for the heels of my blood! Try to divine his glance! No wonder 'twould his eyes that looked the skies rolled round, Since MARIAN first the face soon learned love's sorrow, Bay leaves between two christal walls, Aw'd by a spirit's song. Yet, many are the staff he waved was all the honour o' the Rodes is a' the glory of their\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"biglam/gutenberg-poetry-corpus\")\n",
    "\n",
    "text = dataset[\"train\"][\"line\"]\n",
    "text = ' '.join(text)\n",
    "tokens = text.split()\n",
    "n = 2\n",
    "lant_markov = construieste_lant_markov(tokens, n)\n",
    "text_generat = HAGIFICA(lant_markov, n)\n",
    "print(text_generat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of the generated text:\n",
      "{'neg': 0.118, 'neu': 0.692, 'pos': 0.19, 'compound': 0.9708}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sentiment = SentimentIntensityAnalyzer().polarity_scores(text_generat)\n",
    "print(\"Sentiment of the generated text:\")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sinonime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 0.1% 1.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "drunker revelry, Or in home and kingdoms thus forego To carry speedy succour to that flights of shell, To Phoebus and this morning fills WIth shade the Lonnie_Timmons_III Delight not all; Not only jetted the splendid grand_prize to win her: They prick a bleeding boast, my shall not be united. Since this must be seemed sublime in state, And Lazarus, can go. And \"Mary smooth your bed, Smile soft the youth, with fractured sighs and tears were all their follow out they hands who’re anymore cleared it down without a pause, lightly:_ An Santa_elves of mischief long, Dame Europe has her fields unsown; But that myself smiled amused and felt above them Lament their lord_bless praise, One jotting of their Chevy_HHR_rolling A baby. While dark and ofthe deadly fight; It'sa is useless fairly To stand aloofness was safest For the heels of my blood! Try to divine her glance! No wondered_aloud 'twould his eye that looked that skies rolled round, Since MARIAN second the face soon learned love's sorrow, Bay leaves between two christal walls, Aw'd by a spirit's song. Yet, many are this staff he waved was all ofthe honour o' the Rodes is a' the glory of their\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load('word2vec-google-news-300')\n",
    "\n",
    "def find_synonym(word, topn=5):\n",
    "    try:\n",
    "        embedding = model[word]\n",
    "        similar_words = model.similar_by_vector(embedding, topn=topn)\n",
    "        synonyms = [word for word, _ in similar_words]\n",
    "        return random.choice(synonyms)\n",
    "    except KeyError:\n",
    "        return word\n",
    "\n",
    "def replace_with_synonyms(text):\n",
    "    tokens = text.split()\n",
    "    replaced_tokens = []\n",
    "    for i in range(len(tokens)):\n",
    "        if (i % 3 == 0):\n",
    "            synonym = find_synonym(tokens[i])\n",
    "        else:\n",
    "            synonym = tokens[i]\n",
    "        replaced_tokens.append(synonym)\n",
    "    return ' '.join(replaced_tokens)\n",
    "\n",
    "replaced_text = replace_with_synonyms(text_generat)\n",
    "print(replaced_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
